{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import re\n",
    "import string\n",
    "from rhyme_finder import RhymeFinder\n",
    "import random\n",
    "\n",
    "flags = Namespace(\n",
    "    seq_size=32,\n",
    "    batch_size=16,\n",
    "    num_batches=1000,\n",
    "    embedding_size=128,\n",
    "    lstm_size=128,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['sleeh', 'hcni'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>6 Inch Heel</td>\n",
       "      <td>https://genius.com/The-weeknd-6-inch-heel-lyrics</td>\n",
       "      <td>six inch heel she walked in the club like nobo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Acquainted</td>\n",
       "      <td>https://genius.com/The-weeknd-acquainted-lyrics</td>\n",
       "      <td>baby you're no good\\ncause they warned me 'bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Adaptation</td>\n",
       "      <td>https://genius.com/The-weeknd-adaptation-lyrics</td>\n",
       "      <td>when the sun comes up you're searching for a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>After Hours</td>\n",
       "      <td>https://genius.com/The-weeknd-after-hours-lyrics</td>\n",
       "      <td>thought i almost died in my dream again \\nfigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Airports</td>\n",
       "      <td>https://genius.com/The-weeknd-airports-lyrics</td>\n",
       "      <td>i think i'm fuckin' gone rollin' on this floor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6462</td>\n",
       "      <td>YG</td>\n",
       "      <td>Yo Nigga Ain’t Me</td>\n",
       "      <td>https://genius.com/Yg-yo-nigga-aint-me-lyrics</td>\n",
       "      <td>hook: charlie hood and yg\\nsee shawty be rocki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6463</td>\n",
       "      <td>YG</td>\n",
       "      <td>Yo Pussy</td>\n",
       "      <td>https://genius.com/Yg-yo-pussy-lyrics</td>\n",
       "      <td>raw smooth with a banger now\\ndon't trip \\ni b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6464</td>\n",
       "      <td>YG</td>\n",
       "      <td>You Betta Kno</td>\n",
       "      <td>https://genius.com/Yg-you-betta-kno-lyrics</td>\n",
       "      <td>ay you don't even know it\\ni'm on this bitch\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6465</td>\n",
       "      <td>YG</td>\n",
       "      <td>You Broke</td>\n",
       "      <td>https://genius.com/Yg-you-broke-lyrics</td>\n",
       "      <td>bitch you broke shut up\\ndont talk to me get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6466</td>\n",
       "      <td>YG</td>\n",
       "      <td>Youzza Flip</td>\n",
       "      <td>https://genius.com/Yg-youzza-flip-lyrics</td>\n",
       "      <td>i'm that nigga same old nigga\\nain't shit chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8589 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist              title  \\\n",
       "0     The Weeknd        6 Inch Heel   \n",
       "1     The Weeknd         Acquainted   \n",
       "2     The Weeknd         Adaptation   \n",
       "3     The Weeknd        After Hours   \n",
       "4     The Weeknd           Airports   \n",
       "...          ...                ...   \n",
       "6462          YG  Yo Nigga Ain’t Me   \n",
       "6463          YG           Yo Pussy   \n",
       "6464          YG      You Betta Kno   \n",
       "6465          YG          You Broke   \n",
       "6466          YG        Youzza Flip   \n",
       "\n",
       "                                                   url  \\\n",
       "0     https://genius.com/The-weeknd-6-inch-heel-lyrics   \n",
       "1      https://genius.com/The-weeknd-acquainted-lyrics   \n",
       "2      https://genius.com/The-weeknd-adaptation-lyrics   \n",
       "3     https://genius.com/The-weeknd-after-hours-lyrics   \n",
       "4        https://genius.com/The-weeknd-airports-lyrics   \n",
       "...                                                ...   \n",
       "6462     https://genius.com/Yg-yo-nigga-aint-me-lyrics   \n",
       "6463             https://genius.com/Yg-yo-pussy-lyrics   \n",
       "6464        https://genius.com/Yg-you-betta-kno-lyrics   \n",
       "6465            https://genius.com/Yg-you-broke-lyrics   \n",
       "6466          https://genius.com/Yg-youzza-flip-lyrics   \n",
       "\n",
       "                                                 lyrics  \n",
       "0     six inch heel she walked in the club like nobo...  \n",
       "1     baby you're no good\\ncause they warned me 'bou...  \n",
       "2     when the sun comes up you're searching for a l...  \n",
       "3     thought i almost died in my dream again \\nfigh...  \n",
       "4     i think i'm fuckin' gone rollin' on this floor...  \n",
       "...                                                 ...  \n",
       "6462  hook: charlie hood and yg\\nsee shawty be rocki...  \n",
       "6463  raw smooth with a banger now\\ndon't trip \\ni b...  \n",
       "6464  ay you don't even know it\\ni'm on this bitch\\n...  \n",
       "6465  bitch you broke shut up\\ndont talk to me get y...  \n",
       "6466  i'm that nigga same old nigga\\nain't shit chan...  \n",
       "\n",
       "[8589 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('DataScraper/hiphop_lyrics.csv')\n",
    "df = df.append(pd.read_csv('DataScraper/hiphop_lyrics2.csv'))\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "def clean_lyrics(l):\n",
    "    l = re.sub(r'[\\(\\[].*?[\\)\\]]', '', l)\n",
    "    l = os.linesep.join([s for s in l.splitlines() if s])\n",
    "    l = l.replace('\\r', '').replace('?', '').replace(\"!\", '').replace(',', '').replace('.', '')\n",
    "    l += '\\n'\n",
    "    l = ''.join([i for i in l if i in string.printable])\n",
    "    #l = l.replace('\\n', '$')\n",
    "    return l.lower()\n",
    "\n",
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"e for work she \\n money the for work \\n dollar every worth she's and \\n finish the to start the from \\n money the for worked she money the for worked she \\n witness her was i and everybody murdered she goddamn \\n business nobody's like club the in walked she heel inch six \\n enemy an like stage fucking the killed she then \\n no oh ecstasy it's like veins her through rushing \\n recipe her that's tastes it way the love she \\n hennessy that with ace that up mixing she \\n professional she up it give gotta don't she \\n decimals them and commas uno de \\n mexico of out pesos know you \\n goes she everywhere money money stacking she's \\n money the for work she \\n money the for work she \\n money the for work she \\n money the for work she \\n minute every worth she's but \\n dollar every worth dollar every worth she's and \\n finish the to start the from \\n money the for worked she money the for worked she \\n witness her was i and everybody murdered she goddamn \\n business nobody's like club the in walked she heel inch six\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RhymeFinder(df['lyrics'])\n",
    "\n",
    "corpus = ''.join(list(df['lyrics']))\n",
    "\n",
    "def revert(data):\n",
    "    lines = data.split('\\n')\n",
    "    lines = [' '.join(x.split(' ')[::-1]) for x in lines]\n",
    "    lines = lines[::-1]\n",
    "    lines = ' \\n '.join(lines)\n",
    "    return lines\n",
    "\n",
    "corpus = revert(corpus)\n",
    "\n",
    "rf.find_lines_ending_with_word('inch heels')\n",
    "\n",
    "def get_data_from_file(corpus, batch_size, seq_size):\n",
    "    text = corpus.split(' ')\n",
    "\n",
    "    word_counts = Counter(text)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "    n_vocab = len(int_to_vocab)\n",
    "\n",
    "    print('Vocabulary size', n_vocab)\n",
    "\n",
    "    int_text = [vocab_to_int[w] for w in text]\n",
    "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "    out_text = np.zeros_like(in_text)\n",
    "    out_text[:-1] = in_text[1:]\n",
    "    out_text[-1] = in_text[0]\n",
    "    in_text = np.reshape(in_text, (batch_size, -1))\n",
    "    out_text = np.reshape(out_text, (batch_size, -1))\n",
    "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 74389\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_file(\n",
    "    corpus, flags.batch_size, flags.seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x).float()\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size).float(),\n",
    "                torch.zeros(1, batch_size, self.lstm_size).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModule(\n",
       "  (embedding): Embedding(74389, 128)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (dense): Linear(in_features=128, out_features=74389, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModule(n_vocab, flags.seq_size,\n",
    "                flags.embedding_size, flags.lstm_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoint_pt/model-26000.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()[0]\n",
    "    return [int_to_vocab[choice] for choice in choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line(words, context, min_length=5, max_length=8):\n",
    "    new_word = ''\n",
    "    words = words.split(' ')[::-1]\n",
    "    words_with_context = context.split(' ')[::-1] + words\n",
    "    while True:\n",
    "        new_words = predict(device, model, words_with_context, n_vocab, vocab_to_int, int_to_vocab, top_k=5)\n",
    "        new_word = ''\n",
    "        if len(words) < min_length and '\\n' in new_words:\n",
    "            new_words.remove('\\n')\n",
    "        if len(words) > max_length:\n",
    "            break\n",
    "        new_word = random.choice(new_words)\n",
    "        if new_word == '\\n':\n",
    "            break\n",
    "        words_with_context.append(new_word)\n",
    "        words.append(new_word)\n",
    "    return ' '.join(words[::-1]) + ' \\n '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verse(words, n_lines=8):\n",
    "    lines = []\n",
    "    context = ''\n",
    "    for i in range(n_lines):\n",
    "        line = generate_line(words, context)\n",
    "        potential_rhymes = rf.find_lines_ending_with_word(words)\n",
    "        if len(potential_rhymes) > 0:\n",
    "            res = {k: v for k, v in sorted(potential_rhymes.items(), key=lambda item: item[1])}\n",
    "            prob = 1\n",
    "            keys = list(res.keys())\n",
    "            for i in range(len(keys)):\n",
    "                words = keys[i]\n",
    "                prob /= 2\n",
    "                r = random.random()\n",
    "                if r < prob:\n",
    "                    break\n",
    "        lines.append(line)\n",
    "        context = '\\n ' + lines[-1]\n",
    "    return ''.join(lines[::-1]).replace('\\n ', '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bout to fuck that bitch yes \n",
      "she got y'all know this gangster chest no lisp \n",
      "tried to pull up for the 40000 dollar dress \n",
      "find a stack it up to your so fresh \n",
      "can't even 'cause prom decanter broad \n",
      "if i go to me and your so fresh \n",
      "lays flat where ya ashy to pullup decanter broad \n",
      "niggas know you wear droppin' lenox mall now \n",
      "your ass is that you feel like decanter broad \n",
      "on par and your so fresh \n",
      "got a whole white decanter broad \n",
      "no silencer on that blue state your so fresh \n",
      "scrimmage throw a yellow fify decanter broad \n",
      "and cedar 'till at lenox mall now \n",
      "cake bitch and then i act like decanter broad \n",
      "but we got your spendin money all now \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_verse('all now', n_lines=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
